{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      " 65%|██████▍   | 6406144/9912422 [00:01<00:00, 3632922.19it/s]Extracting data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[ADownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[AExtracting data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 24576/1648877 [00:00<00:06, 233078.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 73728/1648877 [00:00<00:06, 260739.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 147456/1648877 [00:00<00:04, 323140.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 245760/1648877 [00:00<00:03, 403180.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 409600/1648877 [00:01<00:02, 519117.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 598016/1648877 [00:01<00:01, 661200.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 802816/1648877 [00:01<00:01, 825880.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 1081344/1648877 [00:01<00:00, 1044358.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1613824/1648877 [00:01<00:00, 1375287.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[AExtracting data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AExtracting data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "type: <class 'torch.utils.data.dataloader.DataLoader'> \n",
      "\n",
      "name            | type                      | size\n",
      "Num of Batch    |                           | 938\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([64, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "input_size = 28\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                transforms.ToTensor()])\n",
    "data_loader = DataLoader(\n",
    "    datasets.MNIST('C:\\data/mnist/', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "print('type:', type(data_loader), '\\n')\n",
    "\n",
    "first_batch = data_loader.__iter__().__next__()\n",
    "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of Batch', '', len(data_loader)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file. \n",
    "        \"\"\"\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.x = torch.tensor(np.asarray(data.iloc[:,:-1]), dtype=torch.float)\n",
    "        self.x = torch.tensor(np.asarray(data.iloc[:,-1]), dtype=torch.float)\n",
    "        #self.x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "        #self.y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "dataset = CardDataset('C:\\data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
