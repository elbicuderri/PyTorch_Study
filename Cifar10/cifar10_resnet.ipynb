{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable\n",
    "from statistics import mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "batch_size = 100\n",
    "\n",
    "transform = transforms.Compose([\n",
    " transforms.Pad(4),\n",
    " transforms.RandomHorizontalFlip(),\n",
    " transforms.RandomCrop(32),\n",
    " transforms.ToTensor(),\n",
    " transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # only can do to tensor so keep order\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10('C:\\data/cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = datasets.CIFAR10(root='C:\\data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.block12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False)\n",
    "\n",
    "        self.block21 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.block22 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False)\n",
    "\n",
    "        self.block31 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.block32 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0 = self.conv0(x)\n",
    "        out1 = self.block11(out0)\n",
    "        out1 = self.block12(out1)\n",
    "\n",
    "        res2 = self.conv2(out1)\n",
    "        out2 = self.block21(out1)\n",
    "        out2 = self.block22(out2)\n",
    "        out2 += res2\n",
    "        out2 = self.relu(out2)\n",
    "\n",
    "        res3 = self.conv3(out2)\n",
    "        out3 = self.block31(out2)\n",
    "        out3 = self.block32(out3)\n",
    "        out3 += res3\n",
    "        out3 = self.relu(out3)\n",
    "\n",
    "        out3 = self.avg_pool(out3)\n",
    "        out3 = self.flatten(out3)\n",
    "        out = self.fc(out3)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'model.png'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "InTensor = Variable(torch.randn(1, 3, 32, 32)).to(device)\n",
    "make_dot(model(InTensor), params=dict(model.named_parameters())).render(\"model\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 32, 32]             432\n       BatchNorm2d-2           [-1, 16, 32, 32]              32\n              ReLU-3           [-1, 16, 32, 32]               0\n            Conv2d-4           [-1, 16, 32, 32]           2,304\n       BatchNorm2d-5           [-1, 16, 32, 32]              32\n              ReLU-6           [-1, 16, 32, 32]               0\n            Conv2d-7           [-1, 16, 32, 32]           2,304\n       BatchNorm2d-8           [-1, 16, 32, 32]              32\n            Conv2d-9           [-1, 16, 32, 32]           2,304\n      BatchNorm2d-10           [-1, 16, 32, 32]              32\n             ReLU-11           [-1, 16, 32, 32]               0\n           Conv2d-12           [-1, 16, 32, 32]           2,304\n      BatchNorm2d-13           [-1, 16, 32, 32]              32\n           Conv2d-14           [-1, 32, 16, 16]           4,608\n           Conv2d-15           [-1, 32, 16, 16]           4,608\n      BatchNorm2d-16           [-1, 32, 16, 16]              64\n             ReLU-17           [-1, 32, 16, 16]               0\n           Conv2d-18           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-19           [-1, 32, 16, 16]              64\n           Conv2d-20           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-21           [-1, 32, 16, 16]              64\n             ReLU-22           [-1, 32, 16, 16]               0\n           Conv2d-23           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-24           [-1, 32, 16, 16]              64\n             ReLU-25           [-1, 32, 16, 16]               0\n           Conv2d-26             [-1, 64, 8, 8]          18,432\n           Conv2d-27             [-1, 64, 8, 8]          18,432\n      BatchNorm2d-28             [-1, 64, 8, 8]             128\n             ReLU-29             [-1, 64, 8, 8]               0\n           Conv2d-30             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-31             [-1, 64, 8, 8]             128\n           Conv2d-32             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-33             [-1, 64, 8, 8]             128\n             ReLU-34             [-1, 64, 8, 8]               0\n           Conv2d-35             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-36             [-1, 64, 8, 8]             128\n             ReLU-37             [-1, 64, 8, 8]               0\n        AvgPool2d-38             [-1, 64, 1, 1]               0\n          Flatten-39                   [-1, 64]               0\n           Linear-40                   [-1, 10]             650\n================================================================\nTotal params: 195,546\nTrainable params: 195,546\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 2.75\nParams size (MB): 0.75\nEstimated Total Size (MB): 3.51\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/10] Step [100/500] Loss: 0.3297\n",
      "Epoch [1/10] Step [200/500] Loss: 0.4739\n",
      "Epoch [1/10] Step [300/500] Loss: 0.5288\n",
      "Epoch [1/10] Step [400/500] Loss: 0.4637\n",
      "Epoch [1/10] Step [500/500] Loss: 0.2659\n",
      "Epoch [1] Train Loss: 0.4161 Val Loss: 0.5497\n",
      "Epoch [2/10] Step [100/500] Loss: 0.3478\n",
      "Epoch [2/10] Step [200/500] Loss: 0.3011\n",
      "Epoch [2/10] Step [300/500] Loss: 0.4150\n",
      "Epoch [2/10] Step [400/500] Loss: 0.3313\n",
      "Epoch [2/10] Step [500/500] Loss: 0.3554\n",
      "Epoch [2] Train Loss: 0.4067 Val Loss: 0.5482\n",
      "Epoch [3/10] Step [100/500] Loss: 0.3674\n",
      "Epoch [3/10] Step [200/500] Loss: 0.5226\n",
      "Epoch [3/10] Step [300/500] Loss: 0.3693\n",
      "Epoch [3/10] Step [400/500] Loss: 0.4384\n",
      "Epoch [3/10] Step [500/500] Loss: 0.3910\n",
      "Epoch [3] Train Loss: 0.3973 Val Loss: 0.5470\n",
      "Epoch [4/10] Step [100/500] Loss: 0.3294\n",
      "Epoch [4/10] Step [200/500] Loss: 0.3570\n",
      "Epoch [4/10] Step [300/500] Loss: 0.5070\n",
      "Epoch [4/10] Step [400/500] Loss: 0.3626\n",
      "Epoch [4/10] Step [500/500] Loss: 0.4844\n",
      "Epoch [4] Train Loss: 0.3889 Val Loss: 0.5098\n",
      "Epoch [5/10] Step [100/500] Loss: 0.3604\n",
      "Epoch [5/10] Step [200/500] Loss: 0.3520\n",
      "Epoch [5/10] Step [300/500] Loss: 0.4806\n",
      "Epoch [5/10] Step [400/500] Loss: 0.4161\n",
      "Epoch [5/10] Step [500/500] Loss: 0.4217\n",
      "Epoch [5] Train Loss: 0.3776 Val Loss: 0.6045\n",
      "Epoch [6/10] Step [100/500] Loss: 0.3975\n",
      "Epoch [6/10] Step [200/500] Loss: 0.2131\n",
      "Epoch [6/10] Step [300/500] Loss: 0.3689\n",
      "Epoch [6/10] Step [400/500] Loss: 0.3556\n",
      "Epoch [6/10] Step [500/500] Loss: 0.3583\n",
      "Epoch [6] Train Loss: 0.3722 Val Loss: 0.5735\n",
      "Epoch [7/10] Step [100/500] Loss: 0.2818\n",
      "Epoch [7/10] Step [200/500] Loss: 0.5350\n",
      "Epoch [7/10] Step [300/500] Loss: 0.3357\n",
      "Epoch [7/10] Step [400/500] Loss: 0.6112\n",
      "Epoch [7/10] Step [500/500] Loss: 0.5026\n",
      "Epoch [7] Train Loss: 0.3657 Val Loss: 0.5149\n",
      "Epoch [8/10] Step [100/500] Loss: 0.3855\n",
      "Epoch [8/10] Step [200/500] Loss: 0.2250\n",
      "Epoch [8/10] Step [300/500] Loss: 0.4592\n",
      "Epoch [8/10] Step [400/500] Loss: 0.3347\n",
      "Epoch [8/10] Step [500/500] Loss: 0.3409\n",
      "Epoch [8] Train Loss: 0.3583 Val Loss: 0.5262\n",
      "Epoch [9/10] Step [100/500] Loss: 0.5180\n",
      "Epoch [9/10] Step [200/500] Loss: 0.4518\n",
      "Epoch [9/10] Step [300/500] Loss: 0.3109\n",
      "Epoch [9/10] Step [400/500] Loss: 0.3613\n",
      "Epoch [9/10] Step [500/500] Loss: 0.3093\n",
      "Epoch [9] Train Loss: 0.3485 Val Loss: 0.5188\n",
      "Epoch [10/10] Step [100/500] Loss: 0.2824\n",
      "Epoch [10/10] Step [200/500] Loss: 0.2599\n",
      "Epoch [10/10] Step [300/500] Loss: 0.3405\n",
      "Epoch [10/10] Step [400/500] Loss: 0.3578\n",
      "Epoch [10/10] Step [500/500] Loss: 0.4298\n",
      "Epoch [10] Train Loss: 0.3424 Val Loss: 0.5296\n"
     ]
    }
   ],
   "source": [
    "loss_dict = {}\n",
    "val_loss_dict = {}\n",
    "train_step = len(train_loader)\n",
    "val_step = len(valid_loader)\n",
    "epochs = 10\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "    loss_list = [] # losses of i'th epoch\n",
    "    for train_step_idx, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(img)\n",
    "        loss = loss_fn(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        if ((train_step_idx+1) % 100 == 0):\n",
    "            print(f\"Epoch [{i}/{epochs}] Step [{train_step_idx + 1}/{train_step}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    loss_dict[i] = loss_list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss_list = []\n",
    "        for val_step_idx, (val_img, val_label) in enumerate(valid_loader):\n",
    "            val_img = val_img.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "\n",
    "            val_output = model(val_img)\n",
    "            val_loss = loss_fn(val_output, val_label)\n",
    "\n",
    "            val_loss_list.append(val_loss.item())\n",
    "\n",
    "        val_loss_dict[i] = val_loss_list\n",
    "\n",
    "    print(f\"Epoch [{i}] Train Loss: {mean(loss_dict[i]):.4f} Val Loss: {mean(val_loss_dict[i]):.4f}\")\n",
    "    print(\"========================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}