digraph {
	graph [size="25.95,25.95"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	2380399081888 [label=AddmmBackward fillcolor=darkolivegreen1]
	2380399080928 -> 2380399081888
	2380399080928 [label="fc.bias
 (10)" fillcolor=lightblue]
	2380399079536 -> 2380399081888
	2380399079536 [label=ViewBackward]
	2380625491472 -> 2380399079536
	2380625491472 [label=AvgPool2DBackward]
	2380625491136 -> 2380625491472
	2380625491136 [label=ReluBackward0]
	2380625493440 -> 2380625491136
	2380625493440 [label=AddBackward0]
	2380625492144 -> 2380625493440
	2380625492144 [label=CudnnBatchNormBackward]
	2380625493200 -> 2380625492144
	2380625493200 [label=CudnnConvolutionBackward]
	2380625490176 -> 2380625493200
	2380625490176 [label=ReluBackward0]
	2380625493104 -> 2380625490176
	2380625493104 [label=CudnnBatchNormBackward]
	2380625492288 -> 2380625493104
	2380625492288 [label=CudnnConvolutionBackward]
	2380625490800 -> 2380625492288
	2380625490800 [label=CudnnBatchNormBackward]
	2380625490272 -> 2380625490800
	2380625490272 [label=CudnnConvolutionBackward]
	2380625493152 -> 2380625490272
	2380625493152 [label=ReluBackward0]
	2380625493920 -> 2380625493152
	2380625493920 [label=CudnnBatchNormBackward]
	2380625490128 -> 2380625493920
	2380625490128 [label=CudnnConvolutionBackward]
	2380625493632 -> 2380625490128
	2380625493632 [label=ReluBackward0]
	2380625490320 -> 2380625493632
	2380625490320 [label=AddBackward0]
	2380625492960 -> 2380625490320
	2380625492960 [label=CudnnBatchNormBackward]
	2380399074608 -> 2380625492960
	2380399074608 [label=CudnnConvolutionBackward]
	2380625536960 -> 2380399074608
	2380625536960 [label=ReluBackward0]
	2381720471344 -> 2380625536960
	2381720471344 [label=CudnnBatchNormBackward]
	2381720470048 -> 2381720471344
	2381720470048 [label=CudnnConvolutionBackward]
	2381720470288 -> 2381720470048
	2381720470288 [label=CudnnBatchNormBackward]
	2381720470960 -> 2381720470288
	2381720470960 [label=CudnnConvolutionBackward]
	2381720473408 -> 2381720470960
	2381720473408 [label=ReluBackward0]
	2380287691648 -> 2381720473408
	2380287691648 [label=CudnnBatchNormBackward]
	2380287691264 -> 2380287691648
	2380287691264 [label=CudnnConvolutionBackward]
	2380287690784 -> 2380287691264
	2380287690784 [label=CudnnBatchNormBackward]
	2380287691072 -> 2380287690784
	2380287691072 [label=CudnnConvolutionBackward]
	2380287689344 -> 2380287691072
	2380287689344 [label=ReluBackward0]
	2380287690544 -> 2380287689344
	2380287690544 [label=CudnnBatchNormBackward]
	2380287690640 -> 2380287690544
	2380287690640 [label=CudnnConvolutionBackward]
	2380288080528 -> 2380287690640
	2380288080528 [label=CudnnBatchNormBackward]
	2380288080480 -> 2380288080528
	2380288080480 [label=CudnnConvolutionBackward]
	2380288080576 -> 2380288080480
	2380288080576 [label=ReluBackward0]
	2380288081392 -> 2380288080576
	2380288081392 [label=CudnnBatchNormBackward]
	2380399292864 -> 2380288081392
	2380399292864 [label=CudnnConvolutionBackward]
	2380399295216 -> 2380399292864
	2380399295216 [label=ReluBackward0]
	2380399295024 -> 2380399295216
	2380399295024 [label=CudnnBatchNormBackward]
	2380399295696 -> 2380399295024
	2380399295696 [label=CudnnConvolutionBackward]
	2380399293776 -> 2380399295696
	2380399293776 [label="conv0.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	2380399295792 -> 2380399295024
	2380399295792 [label="conv0.1.weight
 (16)" fillcolor=lightblue]
	2380399294400 -> 2380399295024
	2380399294400 [label="conv0.1.bias
 (16)" fillcolor=lightblue]
	2380399294496 -> 2380399292864
	2380399294496 [label="block11.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2380399292672 -> 2380288081392
	2380399292672 [label="block11.1.weight
 (16)" fillcolor=lightblue]
	2380399292816 -> 2380288081392
	2380399292816 [label="block11.1.bias
 (16)" fillcolor=lightblue]
	2380288080672 -> 2380288080480
	2380288080672 [label="block11.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2380288079568 -> 2380288080528
	2380288079568 [label="block11.4.weight
 (16)" fillcolor=lightblue]
	2380288079808 -> 2380288080528
	2380288079808 [label="block11.4.bias
 (16)" fillcolor=lightblue]
	2380288079664 -> 2380287690640
	2380288079664 [label="block12.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2380288080720 -> 2380287690544
	2380288080720 [label="block12.1.weight
 (16)" fillcolor=lightblue]
	2380288079232 -> 2380287690544
	2380288079232 [label="block12.1.bias
 (16)" fillcolor=lightblue]
	2380287692608 -> 2380287691072
	2380287692608 [label="block12.3.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2380287690304 -> 2380287690784
	2380287690304 [label="block12.4.weight
 (16)" fillcolor=lightblue]
	2380287689200 -> 2380287690784
	2380287689200 [label="block12.4.bias
 (16)" fillcolor=lightblue]
	2380287692560 -> 2380287691264
	2380287692560 [label="block21.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2380287690928 -> 2380287691648
	2380287690928 [label="block21.1.weight
 (32)" fillcolor=lightblue]
	2380287689728 -> 2380287691648
	2380287689728 [label="block21.1.bias
 (32)" fillcolor=lightblue]
	2381720471296 -> 2381720470960
	2381720471296 [label="block21.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2381720472256 -> 2381720470288
	2381720472256 [label="block21.4.weight
 (32)" fillcolor=lightblue]
	2381720472304 -> 2381720470288
	2381720472304 [label="block21.4.bias
 (32)" fillcolor=lightblue]
	2381720470000 -> 2381720470048
	2381720470000 [label="block22.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2381720472064 -> 2381720471344
	2381720472064 [label="block22.1.weight
 (32)" fillcolor=lightblue]
	2381720471968 -> 2381720471344
	2381720471968 [label="block22.1.bias
 (32)" fillcolor=lightblue]
	2381720470480 -> 2380399074608
	2381720470480 [label="block22.3.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2380625536768 -> 2380625492960
	2380625536768 [label="block22.4.weight
 (32)" fillcolor=lightblue]
	2380625536384 -> 2380625492960
	2380625536384 [label="block22.4.bias
 (32)" fillcolor=lightblue]
	2380399074032 -> 2380625490320
	2380399074032 [label=CudnnConvolutionBackward]
	2380287690784 -> 2380399074032
	2380625538016 -> 2380399074032
	2380625538016 [label="conv2.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2380625491856 -> 2380625490128
	2380625491856 [label="block31.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2380625493584 -> 2380625493920
	2380625493584 [label="block31.1.weight
 (64)" fillcolor=lightblue]
	2380625491952 -> 2380625493920
	2380625491952 [label="block31.1.bias
 (64)" fillcolor=lightblue]
	2380625493488 -> 2380625490272
	2380625493488 [label="block31.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2380625490848 -> 2380625490800
	2380625490848 [label="block31.4.weight
 (64)" fillcolor=lightblue]
	2380625492096 -> 2380625490800
	2380625492096 [label="block31.4.bias
 (64)" fillcolor=lightblue]
	2380625490512 -> 2380625492288
	2380625490512 [label="block32.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2380625490032 -> 2380625493104
	2380625490032 [label="block32.1.weight
 (64)" fillcolor=lightblue]
	2380625491328 -> 2380625493104
	2380625491328 [label="block32.1.bias
 (64)" fillcolor=lightblue]
	2380625493056 -> 2380625493200
	2380625493056 [label="block32.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2380625491808 -> 2380625492144
	2380625491808 [label="block32.4.weight
 (64)" fillcolor=lightblue]
	2380625493872 -> 2380625492144
	2380625493872 [label="block32.4.bias
 (64)" fillcolor=lightblue]
	2380625492768 -> 2380625493440
	2380625492768 [label=CudnnConvolutionBackward]
	2380625493632 -> 2380625492768
	2380625492336 -> 2380625492768
	2380625492336 [label="conv3.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2380399081168 -> 2380399081888
	2380399081168 [label=TBackward]
	2380625491520 -> 2380399081168
	2380625491520 [label="fc.weight
 (10, 64)" fillcolor=lightblue]
}
