{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\data/cifar10\\cifar-10-python.tar.gz\n",
      "100%|█████████▉| 170123264/170498071 [00:38<00:00, 6353086.86it/s]Extracting C:\\data/cifar10\\cifar-10-python.tar.gz to C:\\data/cifar10\n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    " transforms.Pad(4),\n",
    " transforms.RandomHorizontalFlip(),\n",
    " transforms.RandomCrop(32),\n",
    " transforms.ToTensor(),\n",
    " transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # only can do to tensor so keep order\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10('C:\\data/cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.block11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.block12 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False)\n",
    "\n",
    "        self.block21 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.block22 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False)\n",
    "\n",
    "        self.block31 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.block32 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0 = self.conv0(x)\n",
    "        out1 = self.block11(out0)\n",
    "        out1 = self.block12(out1)\n",
    "\n",
    "        res2 = self.conv2(out1)\n",
    "        out2 = self.block21(out1)\n",
    "        out2 = self.block22(out2)\n",
    "        out2 += res2\n",
    "        out2 = self.relu(out2)\n",
    "        #out2 = nn.ReLU(out2, inplace=True)\n",
    "\n",
    "        res3 = self.conv3(out2)\n",
    "        out3 = self.block31(out2)\n",
    "        out3 = self.block32(out3)\n",
    "        out3 += res3\n",
    "        out3 = self.relu(out3)\n",
    "        #out3 = nn.ReLU(out3, inplace=True)\n",
    "\n",
    "        out3 = self.avg_pool(out3)\n",
    "        out3 = self.flatten(out3)\n",
    "        #out3 = nn.Flatten()(out3)\n",
    "        out = self.fc(out3)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'model.png'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "InTensor = Variable(torch.randn(1, 3, 32, 32)).to(device)\n",
    "make_dot(model(InTensor), params=dict(model.named_parameters())).render(\"model\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 32, 32]             432\n       BatchNorm2d-2           [-1, 16, 32, 32]              32\n              ReLU-3           [-1, 16, 32, 32]               0\n            Conv2d-4           [-1, 16, 32, 32]           2,304\n       BatchNorm2d-5           [-1, 16, 32, 32]              32\n              ReLU-6           [-1, 16, 32, 32]               0\n            Conv2d-7           [-1, 16, 32, 32]           2,304\n       BatchNorm2d-8           [-1, 16, 32, 32]              32\n            Conv2d-9           [-1, 16, 32, 32]           2,304\n      BatchNorm2d-10           [-1, 16, 32, 32]              32\n             ReLU-11           [-1, 16, 32, 32]               0\n           Conv2d-12           [-1, 16, 32, 32]           2,304\n      BatchNorm2d-13           [-1, 16, 32, 32]              32\n           Conv2d-14           [-1, 32, 16, 16]           4,608\n           Conv2d-15           [-1, 32, 16, 16]           4,608\n      BatchNorm2d-16           [-1, 32, 16, 16]              64\n             ReLU-17           [-1, 32, 16, 16]               0\n           Conv2d-18           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-19           [-1, 32, 16, 16]              64\n           Conv2d-20           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-21           [-1, 32, 16, 16]              64\n             ReLU-22           [-1, 32, 16, 16]               0\n           Conv2d-23           [-1, 32, 16, 16]           9,216\n      BatchNorm2d-24           [-1, 32, 16, 16]              64\n             ReLU-25           [-1, 32, 16, 16]               0\n           Conv2d-26             [-1, 64, 8, 8]          18,432\n           Conv2d-27             [-1, 64, 8, 8]          18,432\n      BatchNorm2d-28             [-1, 64, 8, 8]             128\n             ReLU-29             [-1, 64, 8, 8]               0\n           Conv2d-30             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-31             [-1, 64, 8, 8]             128\n           Conv2d-32             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-33             [-1, 64, 8, 8]             128\n             ReLU-34             [-1, 64, 8, 8]               0\n           Conv2d-35             [-1, 64, 8, 8]          36,864\n      BatchNorm2d-36             [-1, 64, 8, 8]             128\n             ReLU-37             [-1, 64, 8, 8]               0\n        AvgPool2d-38             [-1, 64, 1, 1]               0\n          Flatten-39                   [-1, 64]               0\n           Linear-40                   [-1, 10]             650\n================================================================\nTotal params: 195,546\nTrainable params: 195,546\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 2.75\nParams size (MB): 0.75\nEstimated Total Size (MB): 3.51\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}